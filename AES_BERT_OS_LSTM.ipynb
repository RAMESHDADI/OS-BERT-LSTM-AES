{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AES-BERT-OS_LSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGrDj0qIehq8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.read_csv('/content/drive/MyDrive/OS2931.csv',encoding=\"ISO-8859-1\")"
      ],
      "metadata": {
        "id": "iTwfPqxNeorm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fglhzAzig7I",
        "outputId": "ae746a99-dea9-4ac0-b808-d399f9d4cc43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ï»¿iD                                           Response  Reviewer-1  \\\n",
            "0         1  An operating system (OS) is system software th...           4   \n",
            "1         1  An operating system is the most important soft...           5   \n",
            "2         1  Collection of programs that manages hardware r...           2   \n",
            "3         1      It is an interface user and machine(hardware)           2   \n",
            "4         1  An operating system is a software which acts a...           3   \n",
            "...     ...                                                ...         ...   \n",
            "2385      5  Single processor contains only one processer.w...           2   \n",
            "2386      5  Single processor systems are less reliable tha...           3   \n",
            "2387      5  Single processor system contains only one proc...           2   \n",
            "2388      5  Single processor can assign only one task but ...           1   \n",
            "2389      5  Single Processor\\n-> Uses a single cpu\\n-> Eas...           2   \n",
            "\n",
            "      Reviewer-2  \n",
            "0              4  \n",
            "1              5  \n",
            "2              1  \n",
            "3              1  \n",
            "4              2  \n",
            "...          ...  \n",
            "2385           2  \n",
            "2386           3  \n",
            "2387           2  \n",
            "2388           1  \n",
            "2389           2  \n",
            "\n",
            "[2390 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=X[X['ï»¿iD']==3]\n",
        "X = X.dropna(axis=1)\n",
        "y = X['Reviewer-1']\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cq_UgVYeooA",
        "outputId": "d9497949-de33-4794-a754-9794fd2e0d52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1112    3\n",
            "1113    3\n",
            "1114    3\n",
            "1115    2\n",
            "1116    1\n",
            "       ..\n",
            "1419    2\n",
            "1420    1\n",
            "1421    3\n",
            "1422    3\n",
            "1423    1\n",
            "Name: Reviewer-1, Length: 312, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Embedding, LSTM, Dense, Dropout, Lambda, Flatten\n",
        "from keras.models import Sequential, load_model, model_from_config\n",
        "import keras.backend as K\n",
        "\n",
        "def get_model():\n",
        "    \"\"\"Define the model.\"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(300,dropout=0.5,recurrent_dropout=0.4, input_shape=[1, 2944], return_sequences=True))\n",
        "    #model.add(LSTM(300, dropout=0.5, recurrent_dropout=0.4, return_sequences=True))\n",
        "    model.add(LSTM(200, dropout=0.5, recurrent_dropout=0.4, return_sequences=True))\n",
        "    model.add(LSTM(100, return_sequences=True))\n",
        "    model.add(LSTM(64, recurrent_dropout=0.4))\n",
        "    model.add(Dropout(0.4))\n",
        "    model.add(Dense(1, activation='relu'))\n",
        "    model.compile(loss='mean_squared_error', optimizer=tf.optimizers.Adam(lr=0.001),metrics=['accuracy'])\n",
        "    #model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "LaOwQzY7eola"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "use = hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim128/2\")\n",
        "aa=[]"
      ],
      "metadata": {
        "id": "45edYb-meojF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import PunktSentenceTokenizer\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPEF86gKeoeG",
        "outputId": "30520d3c-8a70-43c0-b4aa-5816b0168479"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def essay_to_sentences(essay_v, remove_stopwords):\n",
        "    \"\"\"Sentence tokenize the essay and call essay_to_wordlist() for word tokenization.\"\"\"\n",
        "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "    #tokennizer=PunktSentenceTokenizer(english.pickle)\n",
        "    raw_sentences = tokenizer.tokenize(essay_v.strip())\n",
        "    sentences = []\n",
        "    for raw_sentence in raw_sentences:\n",
        "        if len(raw_sentence) > 0:\n",
        "            sentences.append((raw_sentence))\n",
        "    #print(sentences)\n",
        "    return sentences\n",
        "\n",
        "def makeFeatureVec(words, num_features,n):\n",
        "    \"\"\"Make Feature Vector from the words list of an Essay.\"\"\"\n",
        "    featureVec = np.zeros((n,num_features),dtype=\"float32\")\n",
        "    #success\n",
        "    x=use(words) #length of feature vector is (16,512) and length of use is (16,128)\n",
        "    y=len(x[0])\n",
        "#     featureVec = np.zeros((n,num_features),dtype=\"float32\")\n",
        "    featureVec = np.zeros((n,y),dtype=\"float32\")\n",
        "    featureVec = np.add(featureVec,x).flatten() # getting error while adding vectors\n",
        "    ss=num_features-y\n",
        "#     print(\"diff=\",ss)\n",
        "    featureVec = np.pad(featureVec, (0,ss), 'constant', constant_values=(0, 0))\n",
        "#     print(\"AFTER PADDING\",featureVec,len(featureVec))\n",
        "#     print(\"SHAPE\",featureVec.shape)     \n",
        "    #featureVec = np.divide(featureVec,num_words)\n",
        "    return featureVec\n",
        "\n",
        "def getAvgFeatureVecs(essays, num_features,aa):\n",
        "    \"\"\"Main function to generate the word vectors for word2vec model.\"\"\"\n",
        "    counter = 0\n",
        "    essayFeatureVecs = np.zeros((len(essays),num_features*23),dtype=\"float32\") # creating max length feature vector having 0s\n",
        "#     print(num_features*96)\n",
        "    for essay in essays:\n",
        "        \n",
        "#         #essayFeatureVecs.insert(counter,makeFeatureVec(essay,num_features,aa[counter]))\n",
        "        arr=makeFeatureVec(essay, num_features,aa[counter]).flatten() # getting error here\n",
        "#         print(arr)\n",
        "        ss=(num_features*23)-len(arr)\n",
        "        arr1=np.pad(arr,(0,ss),'constant', constant_values=(0, 0))\n",
        "#         #print(np.add(arr1,np.zeros(num_features*np.max(aa))))\n",
        "        essayFeatureVecs[counter] = np.add(arr1,np.zeros((num_features*23),dtype=\"float\"))\n",
        "#         #makeFeatureVec(essay, num_features,aa[counter]).flatten()\n",
        "#         #print(essayFeatureVecs[0])\n",
        "        counter = counter + 1\n",
        "    return essayFeatureVecs"
      ],
      "metadata": {
        "id": "fdrYlKYseobj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "import tensorflow as tf\n",
        "\n",
        "cv = KFold(n_splits = 5, shuffle = True)\n",
        "results = []\n",
        "y_pred_list = []\n",
        "\n",
        "count = 1\n",
        "for traincv, testcv in cv.split(X):\n",
        "    print(\"\\n--------Fold {}--------\\n\".format(count))\n",
        "    X_test, X_train, y_test, y_train = X.iloc[testcv], X.iloc[traincv], y.iloc[testcv], y.iloc[traincv]\n",
        "    #print(X_train.isna())\n",
        "    train_essays = X_train['Response']\n",
        "    test_essays = X_test['Response']\n",
        "    y_train=y_train\n",
        "    y_test=y_test\n",
        "    num_features = 128\n",
        "    min_word_count = 40\n",
        "    num_workers = 4\n",
        "    context = 10\n",
        "    downsampling = 1e-3\n",
        "    clean_train_essays = []\n",
        "    clean_test_essays=[]\n",
        "    #essays=train_essays\n",
        "    sentences=[]\n",
        "    l1=[]\n",
        "    l2=[]\n",
        "    for essay in train_essays:\n",
        "      sentences += essay_to_sentences(essay, remove_stopwords = False)\n",
        "  \n",
        "      #print(sentences)\n",
        "    for essay in test_essays:\n",
        "      sentences += essay_to_sentences(essay, remove_stopwords = False)\n",
        "\n",
        "    for essay_v in train_essays:\n",
        "      l1.append(len(sent_tokenize(essay_v)))\n",
        "      clean_train_essays.append(essay_to_sentences(essay_v, remove_stopwords=True))\n",
        "      #print(clean_train_essays)\n",
        "    a=np.array(l1)\n",
        "    print(np.max(a))\n",
        "    trainDataVecs = getAvgFeatureVecs(clean_train_essays, num_features,a)\n",
        "    for essay_v in test_essays:\n",
        "      l2.append(len(sent_tokenize(essay_v)))\n",
        "      clean_test_essays.append(essay_to_sentences(essay_v, remove_stopwords=True))\n",
        "    b=np.array(l2)\n",
        "    testDataVecs=getAvgFeatureVecs(clean_test_essays, num_features,b)\n",
        "    trainDataVecs=np.array(trainDataVecs)\n",
        "    testDataVecs = np.array(testDataVecs)\n",
        "    trainDataVecs=np.reshape(trainDataVecs,(trainDataVecs.shape[0],1,trainDataVecs.shape[1]))\n",
        "    testDataVecs = np.reshape(testDataVecs, (testDataVecs.shape[0], 1, testDataVecs.shape[1]))\n",
        "    print(b)\n",
        "    #print(y_train)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(trainDataVecs, y_train, test_size=0.2, random_state=3)\n",
        "    lstm_model = get_model()\n",
        "    history=lstm_model.fit(X_train, y_train, batch_size=16, epochs=50,validation_data=(X_val, y_val))\n",
        "    \n",
        "    #history=lstm_model.fit(trainDataVecs, y_train, batch_size=64, epochs=30)\n",
        "    y_pred=(lstm_model.predict(testDataVecs))\n",
        "    #print(testDataVecs)\n",
        "    # Save any one of the 5 models.\n",
        "    if count == 6:\n",
        "      break\n",
        "         #lstm_model.save('./model_weights/final_lstm.h5')\n",
        "    \n",
        "    # Round y_pred to the nearest integer.\n",
        "    y_pred = np.around(y_pred)\n",
        "    #print(y_pred)\n",
        "    \n",
        "    # Evaluate the model on the evaluation metric. \"Quadratic mean averaged Kappa\"\n",
        "    result = cohen_kappa_score(y_test,y_pred,weights='quadratic')\n",
        "    print(\"Kappa Score: {}\".format(result))\n",
        "    results.append(result)\n",
        "    \n",
        "    count += 1\n",
        "   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oL4VMk2EeoY8",
        "outputId": "ad35b8f9-3102-48e1-8347-e07d9cc91b4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------Fold 1--------\n",
            "\n",
            "18\n",
            "[ 2  2  1  1  1  1  1  1  1  1  2  3  1  1  2  1  1  2  2  1  1  1  2  4\n",
            "  1  1  1  1  9  1  1  1  1  2  2  2  1 12  2  1  1  1  1  2  4  2  4  2\n",
            "  4  2  2  1  1  3  3  1  1  1  1  1  3 16  1]\n",
            "Model: \"sequential_65\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_150 (LSTM)             (None, 1, 300)            3894000   \n",
            "                                                                 \n",
            " lstm_151 (LSTM)             (None, 1, 200)            400800    \n",
            "                                                                 \n",
            " lstm_152 (LSTM)             (None, 1, 100)            120400    \n",
            "                                                                 \n",
            " lstm_153 (LSTM)             (None, 64)                42240     \n",
            "                                                                 \n",
            " dropout_65 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_65 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,457,505\n",
            "Trainable params: 4,457,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 13s 181ms/step - loss: 4.2206 - accuracy: 0.0553 - val_loss: 4.3797 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 2.3628 - accuracy: 0.2060 - val_loss: 0.6053 - val_accuracy: 0.3200\n",
            "Epoch 3/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.8455 - accuracy: 0.3367 - val_loss: 0.6041 - val_accuracy: 0.3400\n",
            "Epoch 4/50\n",
            "13/13 [==============================] - 1s 68ms/step - loss: 0.5971 - accuracy: 0.3367 - val_loss: 0.4268 - val_accuracy: 0.3400\n",
            "Epoch 5/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.5080 - accuracy: 0.3317 - val_loss: 0.3881 - val_accuracy: 0.3400\n",
            "Epoch 6/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.4321 - accuracy: 0.3367 - val_loss: 0.3685 - val_accuracy: 0.3400\n",
            "Epoch 7/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.4269 - accuracy: 0.3417 - val_loss: 0.3531 - val_accuracy: 0.3400\n",
            "Epoch 8/50\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.3967 - accuracy: 0.3467 - val_loss: 0.3482 - val_accuracy: 0.3400\n",
            "Epoch 9/50\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.3976 - accuracy: 0.3367 - val_loss: 0.3383 - val_accuracy: 0.3400\n",
            "Epoch 10/50\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.3986 - accuracy: 0.3367 - val_loss: 0.4831 - val_accuracy: 0.3400\n",
            "Epoch 11/50\n",
            "13/13 [==============================] - 1s 68ms/step - loss: 0.4178 - accuracy: 0.3317 - val_loss: 0.3377 - val_accuracy: 0.3400\n",
            "Epoch 12/50\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.3641 - accuracy: 0.3417 - val_loss: 0.3427 - val_accuracy: 0.3400\n",
            "Epoch 13/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3477 - accuracy: 0.3467 - val_loss: 0.4187 - val_accuracy: 0.3400\n",
            "Epoch 14/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.3189 - accuracy: 0.3417 - val_loss: 0.3532 - val_accuracy: 0.3400\n",
            "Epoch 15/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3546 - accuracy: 0.3417 - val_loss: 0.3452 - val_accuracy: 0.3400\n",
            "Epoch 16/50\n",
            "13/13 [==============================] - 1s 87ms/step - loss: 0.3502 - accuracy: 0.3417 - val_loss: 0.3509 - val_accuracy: 0.3400\n",
            "Epoch 17/50\n",
            "13/13 [==============================] - 1s 105ms/step - loss: 0.3337 - accuracy: 0.3417 - val_loss: 0.3432 - val_accuracy: 0.3400\n",
            "Epoch 18/50\n",
            "13/13 [==============================] - 1s 108ms/step - loss: 0.3158 - accuracy: 0.3568 - val_loss: 0.3761 - val_accuracy: 0.3400\n",
            "Epoch 19/50\n",
            "13/13 [==============================] - 1s 79ms/step - loss: 0.3652 - accuracy: 0.3367 - val_loss: 0.3395 - val_accuracy: 0.3400\n",
            "Epoch 20/50\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.3030 - accuracy: 0.3568 - val_loss: 0.3262 - val_accuracy: 0.3400\n",
            "Epoch 21/50\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.3558 - accuracy: 0.3568 - val_loss: 0.3863 - val_accuracy: 0.3400\n",
            "Epoch 22/50\n",
            "13/13 [==============================] - 1s 68ms/step - loss: 0.3303 - accuracy: 0.3568 - val_loss: 0.3691 - val_accuracy: 0.3400\n",
            "Epoch 23/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3137 - accuracy: 0.3518 - val_loss: 0.3604 - val_accuracy: 0.3400\n",
            "Epoch 24/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3341 - accuracy: 0.3467 - val_loss: 0.4065 - val_accuracy: 0.3400\n",
            "Epoch 25/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.2822 - accuracy: 0.3518 - val_loss: 0.3961 - val_accuracy: 0.3400\n",
            "Epoch 26/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3194 - accuracy: 0.3467 - val_loss: 0.3748 - val_accuracy: 0.3400\n",
            "Epoch 27/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.2911 - accuracy: 0.3467 - val_loss: 0.3497 - val_accuracy: 0.3400\n",
            "Epoch 28/50\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.3181 - accuracy: 0.3518 - val_loss: 0.3706 - val_accuracy: 0.3400\n",
            "Epoch 29/50\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.3032 - accuracy: 0.3467 - val_loss: 0.4064 - val_accuracy: 0.3400\n",
            "Epoch 30/50\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.3244 - accuracy: 0.3518 - val_loss: 0.3806 - val_accuracy: 0.3400\n",
            "Epoch 31/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.2606 - accuracy: 0.3518 - val_loss: 0.4109 - val_accuracy: 0.3400\n",
            "Epoch 32/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.2814 - accuracy: 0.3568 - val_loss: 0.3560 - val_accuracy: 0.3400\n",
            "Epoch 33/50\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.2424 - accuracy: 0.3618 - val_loss: 0.3754 - val_accuracy: 0.3400\n",
            "Epoch 34/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.3073 - accuracy: 0.3417 - val_loss: 0.3598 - val_accuracy: 0.3400\n",
            "Epoch 35/50\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.3083 - accuracy: 0.3467 - val_loss: 0.4241 - val_accuracy: 0.3400\n",
            "Epoch 36/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.2688 - accuracy: 0.3568 - val_loss: 0.3597 - val_accuracy: 0.3400\n",
            "Epoch 37/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.2750 - accuracy: 0.3417 - val_loss: 0.4048 - val_accuracy: 0.3400\n",
            "Epoch 38/50\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.2596 - accuracy: 0.3568 - val_loss: 0.3738 - val_accuracy: 0.3400\n",
            "Epoch 39/50\n",
            "13/13 [==============================] - 1s 68ms/step - loss: 0.2595 - accuracy: 0.3568 - val_loss: 0.3787 - val_accuracy: 0.3400\n",
            "Epoch 40/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.2734 - accuracy: 0.3417 - val_loss: 0.4118 - val_accuracy: 0.3400\n",
            "Epoch 41/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.2742 - accuracy: 0.3568 - val_loss: 0.3924 - val_accuracy: 0.3400\n",
            "Epoch 42/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.2352 - accuracy: 0.3618 - val_loss: 0.3687 - val_accuracy: 0.3400\n",
            "Epoch 43/50\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 0.3061 - accuracy: 0.3467 - val_loss: 0.3923 - val_accuracy: 0.3400\n",
            "Epoch 44/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.2871 - accuracy: 0.3518 - val_loss: 0.3556 - val_accuracy: 0.3400\n",
            "Epoch 45/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.2948 - accuracy: 0.3568 - val_loss: 0.3832 - val_accuracy: 0.3400\n",
            "Epoch 46/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.2794 - accuracy: 0.3518 - val_loss: 0.3730 - val_accuracy: 0.3400\n",
            "Epoch 47/50\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.2246 - accuracy: 0.3518 - val_loss: 0.3886 - val_accuracy: 0.3400\n",
            "Epoch 48/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.2950 - accuracy: 0.3518 - val_loss: 0.3966 - val_accuracy: 0.3400\n",
            "Epoch 49/50\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 0.2565 - accuracy: 0.3417 - val_loss: 0.3577 - val_accuracy: 0.3400\n",
            "Epoch 50/50\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 0.2505 - accuracy: 0.3568 - val_loss: 0.3899 - val_accuracy: 0.3400\n",
            "Kappa Score: 0.6399999999999999\n",
            "\n",
            "--------Fold 2--------\n",
            "\n",
            "18\n",
            "[ 8  1  1  1 15  1  1  1 15 17  1  1  1  2  1  1  1  1  2  2  1  2  2  2\n",
            "  6  2  1  2  1  8  3  1  2 10  2  2  1 12  2  1  1  1  2  8  4  1  2  7\n",
            "  1  1  2  1  1  4  1  1  1  6  1  1  1  1  1]\n",
            "Model: \"sequential_66\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_154 (LSTM)             (None, 1, 300)            3894000   \n",
            "                                                                 \n",
            " lstm_155 (LSTM)             (None, 1, 200)            400800    \n",
            "                                                                 \n",
            " lstm_156 (LSTM)             (None, 1, 100)            120400    \n",
            "                                                                 \n",
            " lstm_157 (LSTM)             (None, 64)                42240     \n",
            "                                                                 \n",
            " dropout_66 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_66 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,457,505\n",
            "Trainable params: 4,457,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 13s 181ms/step - loss: 4.1804 - accuracy: 0.0251 - val_loss: 4.2691 - val_accuracy: 0.0400\n",
            "Epoch 2/50\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 2.3277 - accuracy: 0.1457 - val_loss: 0.5946 - val_accuracy: 0.3200\n",
            "Epoch 3/50\n",
            "13/13 [==============================] - 1s 67ms/step - loss: 0.8281 - accuracy: 0.3819 - val_loss: 0.6863 - val_accuracy: 0.3200\n",
            "Epoch 4/50\n",
            "13/13 [==============================] - 1s 68ms/step - loss: 0.6642 - accuracy: 0.3769 - val_loss: 0.4968 - val_accuracy: 0.3400\n",
            "Epoch 5/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.5727 - accuracy: 0.3819 - val_loss: 0.4818 - val_accuracy: 0.3400\n",
            "Epoch 6/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.5573 - accuracy: 0.3819 - val_loss: 0.4253 - val_accuracy: 0.3400\n",
            "Epoch 7/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.4632 - accuracy: 0.3769 - val_loss: 0.3771 - val_accuracy: 0.3400\n",
            "Epoch 8/50\n",
            "13/13 [==============================] - 1s 68ms/step - loss: 0.4205 - accuracy: 0.3819 - val_loss: 0.3999 - val_accuracy: 0.3400\n",
            "Epoch 9/50\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.4290 - accuracy: 0.3819 - val_loss: 0.3688 - val_accuracy: 0.3400\n",
            "Epoch 10/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.4116 - accuracy: 0.3769 - val_loss: 0.3802 - val_accuracy: 0.3400\n",
            "Epoch 11/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.4101 - accuracy: 0.3769 - val_loss: 0.3341 - val_accuracy: 0.3400\n",
            "Epoch 12/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.3545 - accuracy: 0.3819 - val_loss: 0.3391 - val_accuracy: 0.3400\n",
            "Epoch 13/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.4171 - accuracy: 0.3769 - val_loss: 0.3599 - val_accuracy: 0.3400\n",
            "Epoch 14/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3804 - accuracy: 0.3819 - val_loss: 0.3755 - val_accuracy: 0.3400\n",
            "Epoch 15/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3387 - accuracy: 0.3869 - val_loss: 0.3387 - val_accuracy: 0.3400\n",
            "Epoch 16/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3627 - accuracy: 0.3819 - val_loss: 0.3690 - val_accuracy: 0.3400\n",
            "Epoch 17/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3640 - accuracy: 0.3869 - val_loss: 0.3524 - val_accuracy: 0.3400\n",
            "Epoch 18/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3719 - accuracy: 0.3769 - val_loss: 0.4298 - val_accuracy: 0.3400\n",
            "Epoch 19/50\n",
            "13/13 [==============================] - 1s 68ms/step - loss: 0.3664 - accuracy: 0.3819 - val_loss: 0.4476 - val_accuracy: 0.3400\n",
            "Epoch 20/50\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.3346 - accuracy: 0.3769 - val_loss: 0.3831 - val_accuracy: 0.3400\n",
            "Epoch 21/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3343 - accuracy: 0.3869 - val_loss: 0.3728 - val_accuracy: 0.3400\n",
            "Epoch 22/50\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.3500 - accuracy: 0.3869 - val_loss: 0.4073 - val_accuracy: 0.3400\n",
            "Epoch 23/50\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.3785 - accuracy: 0.3869 - val_loss: 0.4487 - val_accuracy: 0.3400\n",
            "Epoch 24/50\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.3409 - accuracy: 0.3819 - val_loss: 0.4010 - val_accuracy: 0.3400\n",
            "Epoch 25/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3016 - accuracy: 0.3819 - val_loss: 0.3708 - val_accuracy: 0.3400\n",
            "Epoch 26/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3071 - accuracy: 0.3819 - val_loss: 0.4229 - val_accuracy: 0.3400\n",
            "Epoch 27/50\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.2946 - accuracy: 0.3869 - val_loss: 0.4258 - val_accuracy: 0.3400\n",
            "Epoch 28/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3413 - accuracy: 0.3769 - val_loss: 0.4882 - val_accuracy: 0.3400\n",
            "Epoch 29/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3567 - accuracy: 0.3769 - val_loss: 0.3934 - val_accuracy: 0.3400\n",
            "Epoch 30/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3503 - accuracy: 0.3869 - val_loss: 0.4816 - val_accuracy: 0.3400\n",
            "Epoch 31/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3744 - accuracy: 0.3819 - val_loss: 0.3839 - val_accuracy: 0.3400\n",
            "Epoch 32/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3418 - accuracy: 0.3719 - val_loss: 0.3943 - val_accuracy: 0.3400\n",
            "Epoch 33/50\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.3529 - accuracy: 0.3819 - val_loss: 0.4214 - val_accuracy: 0.3400\n",
            "Epoch 34/50\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.3306 - accuracy: 0.3869 - val_loss: 0.3839 - val_accuracy: 0.3400\n",
            "Epoch 35/50\n",
            "13/13 [==============================] - 1s 68ms/step - loss: 0.2747 - accuracy: 0.3819 - val_loss: 0.3854 - val_accuracy: 0.3400\n",
            "Epoch 36/50\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.3029 - accuracy: 0.3869 - val_loss: 0.4249 - val_accuracy: 0.3400\n",
            "Epoch 37/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.3369 - accuracy: 0.3869 - val_loss: 0.3902 - val_accuracy: 0.3400\n",
            "Epoch 38/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.3036 - accuracy: 0.3819 - val_loss: 0.4028 - val_accuracy: 0.3400\n",
            "Epoch 39/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3695 - accuracy: 0.3819 - val_loss: 0.4468 - val_accuracy: 0.3400\n",
            "Epoch 40/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3323 - accuracy: 0.3819 - val_loss: 0.4064 - val_accuracy: 0.3400\n",
            "Epoch 41/50\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.2913 - accuracy: 0.3869 - val_loss: 0.4025 - val_accuracy: 0.3400\n",
            "Epoch 42/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.2953 - accuracy: 0.3869 - val_loss: 0.4491 - val_accuracy: 0.3400\n",
            "Epoch 43/50\n",
            "13/13 [==============================] - 1s 68ms/step - loss: 0.3117 - accuracy: 0.3819 - val_loss: 0.4321 - val_accuracy: 0.3400\n",
            "Epoch 44/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3179 - accuracy: 0.3869 - val_loss: 0.4145 - val_accuracy: 0.3400\n",
            "Epoch 45/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.2672 - accuracy: 0.3869 - val_loss: 0.5149 - val_accuracy: 0.3400\n",
            "Epoch 46/50\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.2726 - accuracy: 0.3769 - val_loss: 0.4123 - val_accuracy: 0.3400\n",
            "Epoch 47/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.2763 - accuracy: 0.3869 - val_loss: 0.4664 - val_accuracy: 0.3400\n",
            "Epoch 48/50\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.2623 - accuracy: 0.3869 - val_loss: 0.4286 - val_accuracy: 0.3400\n",
            "Epoch 49/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3018 - accuracy: 0.3869 - val_loss: 0.4501 - val_accuracy: 0.3400\n",
            "Epoch 50/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3082 - accuracy: 0.3869 - val_loss: 0.4272 - val_accuracy: 0.3400\n",
            "Kappa Score: 0.6440677966101696\n",
            "\n",
            "--------Fold 3--------\n",
            "\n",
            "17\n",
            "[ 2  1  1  1  2  3  1  1  1  2  1  2  3  1  1  1  1  2  2  1  1  2  1  2\n",
            "  2  2  1 12  2  1  1  1  2 18  1  1  1  2  1  2  7  2  2  3  7  4  1  3\n",
            "  2  1  1  1  1  1  1  1  1  3  4  4  1  1]\n",
            "Model: \"sequential_67\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_158 (LSTM)             (None, 1, 300)            3894000   \n",
            "                                                                 \n",
            " lstm_159 (LSTM)             (None, 1, 200)            400800    \n",
            "                                                                 \n",
            " lstm_160 (LSTM)             (None, 1, 100)            120400    \n",
            "                                                                 \n",
            " lstm_161 (LSTM)             (None, 64)                42240     \n",
            "                                                                 \n",
            " dropout_67 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_67 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,457,505\n",
            "Trainable params: 4,457,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 13s 183ms/step - loss: 4.4263 - accuracy: 0.0350 - val_loss: 3.0860 - val_accuracy: 0.0400\n",
            "Epoch 2/50\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 2.5236 - accuracy: 0.1200 - val_loss: 0.4808 - val_accuracy: 0.4600\n",
            "Epoch 3/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.9725 - accuracy: 0.3500 - val_loss: 0.3888 - val_accuracy: 0.4600\n",
            "Epoch 4/50\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.8288 - accuracy: 0.3550 - val_loss: 0.3722 - val_accuracy: 0.4600\n",
            "Epoch 5/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.6011 - accuracy: 0.3550 - val_loss: 0.3384 - val_accuracy: 0.4400\n",
            "Epoch 6/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.6528 - accuracy: 0.3500 - val_loss: 0.2964 - val_accuracy: 0.4400\n",
            "Epoch 7/50\n",
            "13/13 [==============================] - 1s 73ms/step - loss: 0.4747 - accuracy: 0.3600 - val_loss: 0.2546 - val_accuracy: 0.4400\n",
            "Epoch 8/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.4562 - accuracy: 0.3600 - val_loss: 0.2257 - val_accuracy: 0.4400\n",
            "Epoch 9/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.4640 - accuracy: 0.3550 - val_loss: 0.2319 - val_accuracy: 0.4400\n",
            "Epoch 10/50\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.3669 - accuracy: 0.3600 - val_loss: 0.1995 - val_accuracy: 0.4400\n",
            "Epoch 11/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.4055 - accuracy: 0.3600 - val_loss: 0.1987 - val_accuracy: 0.4400\n",
            "Epoch 12/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.4302 - accuracy: 0.3650 - val_loss: 0.2089 - val_accuracy: 0.4400\n",
            "Epoch 13/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3799 - accuracy: 0.3700 - val_loss: 0.2088 - val_accuracy: 0.4400\n",
            "Epoch 14/50\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 0.3434 - accuracy: 0.3500 - val_loss: 0.2297 - val_accuracy: 0.4400\n",
            "Epoch 15/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.3960 - accuracy: 0.3700 - val_loss: 0.2452 - val_accuracy: 0.4400\n",
            "Epoch 16/50\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 0.3339 - accuracy: 0.3600 - val_loss: 0.2201 - val_accuracy: 0.4400\n",
            "Epoch 17/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3123 - accuracy: 0.3600 - val_loss: 0.2178 - val_accuracy: 0.4400\n",
            "Epoch 18/50\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 0.3324 - accuracy: 0.3700 - val_loss: 0.2232 - val_accuracy: 0.4400\n",
            "Epoch 19/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3437 - accuracy: 0.3600 - val_loss: 0.2328 - val_accuracy: 0.4400\n",
            "Epoch 20/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3747 - accuracy: 0.3600 - val_loss: 0.2413 - val_accuracy: 0.4400\n",
            "Epoch 21/50\n",
            "13/13 [==============================] - 1s 73ms/step - loss: 0.2754 - accuracy: 0.3700 - val_loss: 0.2478 - val_accuracy: 0.4400\n",
            "Epoch 22/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.3324 - accuracy: 0.3600 - val_loss: 0.2590 - val_accuracy: 0.4400\n",
            "Epoch 23/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.3279 - accuracy: 0.3600 - val_loss: 0.2564 - val_accuracy: 0.4400\n",
            "Epoch 24/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.3297 - accuracy: 0.3550 - val_loss: 0.2435 - val_accuracy: 0.4400\n",
            "Epoch 25/50\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 0.2815 - accuracy: 0.3550 - val_loss: 0.2355 - val_accuracy: 0.4400\n",
            "Epoch 26/50\n",
            "13/13 [==============================] - 1s 74ms/step - loss: 0.2325 - accuracy: 0.3700 - val_loss: 0.2468 - val_accuracy: 0.4400\n",
            "Epoch 27/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.2253 - accuracy: 0.3750 - val_loss: 0.2354 - val_accuracy: 0.4400\n",
            "Epoch 28/50\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 0.3311 - accuracy: 0.3500 - val_loss: 0.2306 - val_accuracy: 0.4400\n",
            "Epoch 29/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.3092 - accuracy: 0.3700 - val_loss: 0.2441 - val_accuracy: 0.4400\n",
            "Epoch 30/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3093 - accuracy: 0.3650 - val_loss: 0.2460 - val_accuracy: 0.4400\n",
            "Epoch 31/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.2606 - accuracy: 0.3750 - val_loss: 0.2366 - val_accuracy: 0.4400\n",
            "Epoch 32/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.2759 - accuracy: 0.3700 - val_loss: 0.2527 - val_accuracy: 0.4400\n",
            "Epoch 33/50\n",
            "13/13 [==============================] - 1s 73ms/step - loss: 0.2925 - accuracy: 0.3500 - val_loss: 0.2425 - val_accuracy: 0.4400\n",
            "Epoch 34/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.2676 - accuracy: 0.3550 - val_loss: 0.2462 - val_accuracy: 0.4400\n",
            "Epoch 35/50\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 0.3134 - accuracy: 0.3650 - val_loss: 0.2446 - val_accuracy: 0.4400\n",
            "Epoch 36/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.3196 - accuracy: 0.3800 - val_loss: 0.2338 - val_accuracy: 0.4400\n",
            "Epoch 37/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.2459 - accuracy: 0.3800 - val_loss: 0.2374 - val_accuracy: 0.4400\n",
            "Epoch 38/50\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 0.2728 - accuracy: 0.3650 - val_loss: 0.2416 - val_accuracy: 0.4400\n",
            "Epoch 39/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.2581 - accuracy: 0.3700 - val_loss: 0.2894 - val_accuracy: 0.4400\n",
            "Epoch 40/50\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.2643 - accuracy: 0.3650 - val_loss: 0.2416 - val_accuracy: 0.4400\n",
            "Epoch 41/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.2846 - accuracy: 0.3600 - val_loss: 0.2252 - val_accuracy: 0.4400\n",
            "Epoch 42/50\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 0.2341 - accuracy: 0.3750 - val_loss: 0.2366 - val_accuracy: 0.4400\n",
            "Epoch 43/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.2827 - accuracy: 0.3650 - val_loss: 0.2613 - val_accuracy: 0.4400\n",
            "Epoch 44/50\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 0.2942 - accuracy: 0.3550 - val_loss: 0.2495 - val_accuracy: 0.4400\n",
            "Epoch 45/50\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 0.2538 - accuracy: 0.3650 - val_loss: 0.2445 - val_accuracy: 0.4400\n",
            "Epoch 46/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.2507 - accuracy: 0.3650 - val_loss: 0.2713 - val_accuracy: 0.4400\n",
            "Epoch 47/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.2575 - accuracy: 0.3700 - val_loss: 0.2457 - val_accuracy: 0.4400\n",
            "Epoch 48/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.2577 - accuracy: 0.3650 - val_loss: 0.2415 - val_accuracy: 0.4400\n",
            "Epoch 49/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.2678 - accuracy: 0.3650 - val_loss: 0.2545 - val_accuracy: 0.4400\n",
            "Epoch 50/50\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 0.2693 - accuracy: 0.3700 - val_loss: 0.2328 - val_accuracy: 0.4400\n",
            "Kappa Score: 0.33194706994328926\n",
            "\n",
            "--------Fold 4--------\n",
            "\n",
            "18\n",
            "[1 1 1 1 1 3 1 1 2 1 1 1 1 1 1 1 1 1 2 2 1 8 2 1 1 1 1 1 1 1 3 1 2 4 1 5 7\n",
            " 1 2 1 1 1 1 1 2 1 1 1 1 2 1 1 1 3 1 7 1 1 1 1 2 3]\n",
            "Model: \"sequential_68\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_162 (LSTM)             (None, 1, 300)            3894000   \n",
            "                                                                 \n",
            " lstm_163 (LSTM)             (None, 1, 200)            400800    \n",
            "                                                                 \n",
            " lstm_164 (LSTM)             (None, 1, 100)            120400    \n",
            "                                                                 \n",
            " lstm_165 (LSTM)             (None, 64)                42240     \n",
            "                                                                 \n",
            " dropout_68 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_68 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,457,505\n",
            "Trainable params: 4,457,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 14s 181ms/step - loss: 4.6173 - accuracy: 0.0350 - val_loss: 3.2763 - val_accuracy: 0.0400\n",
            "Epoch 2/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 2.7645 - accuracy: 0.1450 - val_loss: 0.5259 - val_accuracy: 0.4200\n",
            "Epoch 3/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.9980 - accuracy: 0.3400 - val_loss: 0.3738 - val_accuracy: 0.4200\n",
            "Epoch 4/50\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.7499 - accuracy: 0.3400 - val_loss: 0.3225 - val_accuracy: 0.4200\n",
            "Epoch 5/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.6396 - accuracy: 0.3350 - val_loss: 0.2828 - val_accuracy: 0.4200\n",
            "Epoch 6/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.6259 - accuracy: 0.3300 - val_loss: 0.2377 - val_accuracy: 0.4200\n",
            "Epoch 7/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.4991 - accuracy: 0.3300 - val_loss: 0.2108 - val_accuracy: 0.4200\n",
            "Epoch 8/50\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.4741 - accuracy: 0.3350 - val_loss: 0.2020 - val_accuracy: 0.4200\n",
            "Epoch 9/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.4585 - accuracy: 0.3250 - val_loss: 0.1965 - val_accuracy: 0.4200\n",
            "Epoch 10/50\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.4976 - accuracy: 0.3400 - val_loss: 0.2137 - val_accuracy: 0.4200\n",
            "Epoch 11/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.4457 - accuracy: 0.3400 - val_loss: 0.2318 - val_accuracy: 0.4200\n",
            "Epoch 12/50\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 0.4103 - accuracy: 0.3400 - val_loss: 0.2270 - val_accuracy: 0.4200\n",
            "Epoch 13/50\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.4234 - accuracy: 0.3400 - val_loss: 0.2240 - val_accuracy: 0.4200\n",
            "Epoch 14/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3696 - accuracy: 0.3400 - val_loss: 0.2143 - val_accuracy: 0.4200\n",
            "Epoch 15/50\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 0.4221 - accuracy: 0.3350 - val_loss: 0.2253 - val_accuracy: 0.4200\n",
            "Epoch 16/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.3905 - accuracy: 0.3300 - val_loss: 0.2748 - val_accuracy: 0.4200\n",
            "Epoch 17/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.3859 - accuracy: 0.3450 - val_loss: 0.2297 - val_accuracy: 0.4200\n",
            "Epoch 18/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.4294 - accuracy: 0.3450 - val_loss: 0.2513 - val_accuracy: 0.4200\n",
            "Epoch 19/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3554 - accuracy: 0.3400 - val_loss: 0.2200 - val_accuracy: 0.4200\n",
            "Epoch 20/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.3357 - accuracy: 0.3500 - val_loss: 0.2358 - val_accuracy: 0.4200\n",
            "Epoch 21/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.3559 - accuracy: 0.3450 - val_loss: 0.2177 - val_accuracy: 0.4200\n",
            "Epoch 22/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.4139 - accuracy: 0.3450 - val_loss: 0.2189 - val_accuracy: 0.4200\n",
            "Epoch 23/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.3524 - accuracy: 0.3350 - val_loss: 0.2264 - val_accuracy: 0.4200\n",
            "Epoch 24/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.3811 - accuracy: 0.3500 - val_loss: 0.2151 - val_accuracy: 0.4200\n",
            "Epoch 25/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.3330 - accuracy: 0.3400 - val_loss: 0.2188 - val_accuracy: 0.4200\n",
            "Epoch 26/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.3466 - accuracy: 0.3400 - val_loss: 0.2282 - val_accuracy: 0.4200\n",
            "Epoch 27/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.3553 - accuracy: 0.3400 - val_loss: 0.2186 - val_accuracy: 0.4200\n",
            "Epoch 28/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.3112 - accuracy: 0.3400 - val_loss: 0.2110 - val_accuracy: 0.4200\n",
            "Epoch 29/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.3712 - accuracy: 0.3500 - val_loss: 0.2352 - val_accuracy: 0.4200\n",
            "Epoch 30/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.3234 - accuracy: 0.3450 - val_loss: 0.2168 - val_accuracy: 0.4200\n",
            "Epoch 31/50\n",
            "13/13 [==============================] - 1s 73ms/step - loss: 0.3454 - accuracy: 0.3350 - val_loss: 0.2336 - val_accuracy: 0.4200\n",
            "Epoch 32/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.3086 - accuracy: 0.3600 - val_loss: 0.2431 - val_accuracy: 0.4200\n",
            "Epoch 33/50\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 0.3267 - accuracy: 0.3450 - val_loss: 0.2551 - val_accuracy: 0.4200\n",
            "Epoch 34/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.3422 - accuracy: 0.3450 - val_loss: 0.2690 - val_accuracy: 0.4200\n",
            "Epoch 35/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.3489 - accuracy: 0.3500 - val_loss: 0.2357 - val_accuracy: 0.4200\n",
            "Epoch 36/50\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 0.3077 - accuracy: 0.3500 - val_loss: 0.2200 - val_accuracy: 0.4200\n",
            "Epoch 37/50\n",
            "13/13 [==============================] - 1s 73ms/step - loss: 0.3619 - accuracy: 0.3450 - val_loss: 0.2389 - val_accuracy: 0.4200\n",
            "Epoch 38/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3500 - accuracy: 0.3450 - val_loss: 0.2282 - val_accuracy: 0.4200\n",
            "Epoch 39/50\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.3358 - accuracy: 0.3300 - val_loss: 0.2308 - val_accuracy: 0.4200\n",
            "Epoch 40/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.3038 - accuracy: 0.3450 - val_loss: 0.2258 - val_accuracy: 0.4200\n",
            "Epoch 41/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3123 - accuracy: 0.3450 - val_loss: 0.2362 - val_accuracy: 0.4200\n",
            "Epoch 42/50\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.3638 - accuracy: 0.3400 - val_loss: 0.2362 - val_accuracy: 0.4200\n",
            "Epoch 43/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3064 - accuracy: 0.3400 - val_loss: 0.2173 - val_accuracy: 0.4200\n",
            "Epoch 44/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.3267 - accuracy: 0.3450 - val_loss: 0.2280 - val_accuracy: 0.4200\n",
            "Epoch 45/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.3250 - accuracy: 0.3350 - val_loss: 0.2319 - val_accuracy: 0.4200\n",
            "Epoch 46/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3255 - accuracy: 0.3350 - val_loss: 0.2144 - val_accuracy: 0.4200\n",
            "Epoch 47/50\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.2736 - accuracy: 0.3500 - val_loss: 0.2184 - val_accuracy: 0.4200\n",
            "Epoch 48/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.3239 - accuracy: 0.3400 - val_loss: 0.2111 - val_accuracy: 0.4200\n",
            "Epoch 49/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.2747 - accuracy: 0.3500 - val_loss: 0.2138 - val_accuracy: 0.4200\n",
            "Epoch 50/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3160 - accuracy: 0.3500 - val_loss: 0.2142 - val_accuracy: 0.4200\n",
            "Kappa Score: 0.6548453608247422\n",
            "\n",
            "--------Fold 5--------\n",
            "\n",
            "18\n",
            "[ 1  1  5  2  3  1  1  1  2  1  1  1  1  1  1  1  1  1  2  1  1  1 10  1\n",
            "  2  1  1  7  1  3  3  2  3  1 16 16  2  1  2  1  1  6  1  1  3  1  1  2\n",
            "  6  1  3  8  1  2  2  3  3  1  1  1  1  1]\n",
            "Model: \"sequential_69\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_166 (LSTM)             (None, 1, 300)            3894000   \n",
            "                                                                 \n",
            " lstm_167 (LSTM)             (None, 1, 200)            400800    \n",
            "                                                                 \n",
            " lstm_168 (LSTM)             (None, 1, 100)            120400    \n",
            "                                                                 \n",
            " lstm_169 (LSTM)             (None, 64)                42240     \n",
            "                                                                 \n",
            " dropout_69 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_69 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,457,505\n",
            "Trainable params: 4,457,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 14s 190ms/step - loss: 4.5605 - accuracy: 0.0300 - val_loss: 3.9162 - val_accuracy: 0.0400\n",
            "Epoch 2/50\n",
            "13/13 [==============================] - 1s 73ms/step - loss: 2.4955 - accuracy: 0.1450 - val_loss: 0.8584 - val_accuracy: 0.3200\n",
            "Epoch 3/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.9827 - accuracy: 0.3400 - val_loss: 0.6293 - val_accuracy: 0.3200\n",
            "Epoch 4/50\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 0.6511 - accuracy: 0.3350 - val_loss: 0.4705 - val_accuracy: 0.3000\n",
            "Epoch 5/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.5843 - accuracy: 0.3400 - val_loss: 0.4354 - val_accuracy: 0.3000\n",
            "Epoch 6/50\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 0.4994 - accuracy: 0.3400 - val_loss: 0.4039 - val_accuracy: 0.3000\n",
            "Epoch 7/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.4793 - accuracy: 0.3350 - val_loss: 0.3785 - val_accuracy: 0.3000\n",
            "Epoch 8/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3800 - accuracy: 0.3400 - val_loss: 0.3457 - val_accuracy: 0.3000\n",
            "Epoch 9/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3900 - accuracy: 0.3450 - val_loss: 0.3484 - val_accuracy: 0.3000\n",
            "Epoch 10/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3455 - accuracy: 0.3350 - val_loss: 0.3949 - val_accuracy: 0.3000\n",
            "Epoch 11/50\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 0.3378 - accuracy: 0.3450 - val_loss: 0.3815 - val_accuracy: 0.3000\n",
            "Epoch 12/50\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 0.3463 - accuracy: 0.3400 - val_loss: 0.4110 - val_accuracy: 0.3000\n",
            "Epoch 13/50\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 0.3290 - accuracy: 0.3500 - val_loss: 0.3780 - val_accuracy: 0.3000\n",
            "Epoch 14/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.4138 - accuracy: 0.3450 - val_loss: 0.4544 - val_accuracy: 0.3000\n",
            "Epoch 15/50\n",
            "13/13 [==============================] - 1s 85ms/step - loss: 0.3391 - accuracy: 0.3500 - val_loss: 0.4185 - val_accuracy: 0.3000\n",
            "Epoch 16/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.3557 - accuracy: 0.3450 - val_loss: 0.3833 - val_accuracy: 0.3000\n",
            "Epoch 17/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.3805 - accuracy: 0.3400 - val_loss: 0.3629 - val_accuracy: 0.3000\n",
            "Epoch 18/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.4157 - accuracy: 0.3450 - val_loss: 0.3776 - val_accuracy: 0.3000\n",
            "Epoch 19/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.3476 - accuracy: 0.3450 - val_loss: 0.4103 - val_accuracy: 0.3000\n",
            "Epoch 20/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3177 - accuracy: 0.3450 - val_loss: 0.3668 - val_accuracy: 0.3000\n",
            "Epoch 21/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3335 - accuracy: 0.3400 - val_loss: 0.4421 - val_accuracy: 0.3000\n",
            "Epoch 22/50\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 0.2806 - accuracy: 0.3450 - val_loss: 0.3639 - val_accuracy: 0.3000\n",
            "Epoch 23/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.3533 - accuracy: 0.3500 - val_loss: 0.3694 - val_accuracy: 0.3000\n",
            "Epoch 24/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.2890 - accuracy: 0.3450 - val_loss: 0.4232 - val_accuracy: 0.3000\n",
            "Epoch 25/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.2747 - accuracy: 0.3450 - val_loss: 0.3648 - val_accuracy: 0.3000\n",
            "Epoch 26/50\n",
            "13/13 [==============================] - 1s 69ms/step - loss: 0.3510 - accuracy: 0.3450 - val_loss: 0.3632 - val_accuracy: 0.3000\n",
            "Epoch 27/50\n",
            "13/13 [==============================] - 1s 73ms/step - loss: 0.3389 - accuracy: 0.3500 - val_loss: 0.4754 - val_accuracy: 0.3000\n",
            "Epoch 28/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.3335 - accuracy: 0.3450 - val_loss: 0.3762 - val_accuracy: 0.3000\n",
            "Epoch 29/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.2913 - accuracy: 0.3450 - val_loss: 0.3945 - val_accuracy: 0.3000\n",
            "Epoch 30/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.2899 - accuracy: 0.3500 - val_loss: 0.3899 - val_accuracy: 0.3000\n",
            "Epoch 31/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.3178 - accuracy: 0.3350 - val_loss: 0.3476 - val_accuracy: 0.3000\n",
            "Epoch 32/50\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 0.2959 - accuracy: 0.3500 - val_loss: 0.3879 - val_accuracy: 0.3000\n",
            "Epoch 33/50\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 0.2884 - accuracy: 0.3350 - val_loss: 0.4353 - val_accuracy: 0.3000\n",
            "Epoch 34/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.2823 - accuracy: 0.3500 - val_loss: 0.3695 - val_accuracy: 0.3000\n",
            "Epoch 35/50\n",
            "13/13 [==============================] - 1s 73ms/step - loss: 0.3047 - accuracy: 0.3500 - val_loss: 0.3998 - val_accuracy: 0.3000\n",
            "Epoch 36/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.2807 - accuracy: 0.3450 - val_loss: 0.3865 - val_accuracy: 0.3000\n",
            "Epoch 37/50\n",
            "13/13 [==============================] - 1s 73ms/step - loss: 0.2686 - accuracy: 0.3500 - val_loss: 0.3896 - val_accuracy: 0.3000\n",
            "Epoch 38/50\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 0.3256 - accuracy: 0.3550 - val_loss: 0.4940 - val_accuracy: 0.3000\n",
            "Epoch 39/50\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 0.3289 - accuracy: 0.3500 - val_loss: 0.3815 - val_accuracy: 0.3000\n",
            "Epoch 40/50\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 0.3076 - accuracy: 0.3450 - val_loss: 0.3902 - val_accuracy: 0.3000\n",
            "Epoch 41/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.2674 - accuracy: 0.3500 - val_loss: 0.3840 - val_accuracy: 0.3000\n",
            "Epoch 42/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.2755 - accuracy: 0.3450 - val_loss: 0.3807 - val_accuracy: 0.3000\n",
            "Epoch 43/50\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 0.2661 - accuracy: 0.3450 - val_loss: 0.4266 - val_accuracy: 0.3000\n",
            "Epoch 44/50\n",
            "13/13 [==============================] - 1s 73ms/step - loss: 0.2213 - accuracy: 0.3500 - val_loss: 0.3646 - val_accuracy: 0.3000\n",
            "Epoch 45/50\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 0.2858 - accuracy: 0.3500 - val_loss: 0.3702 - val_accuracy: 0.3000\n",
            "Epoch 46/50\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 0.2831 - accuracy: 0.3450 - val_loss: 0.3711 - val_accuracy: 0.3000\n",
            "Epoch 47/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.2918 - accuracy: 0.3500 - val_loss: 0.4444 - val_accuracy: 0.3000\n",
            "Epoch 48/50\n",
            "13/13 [==============================] - 1s 72ms/step - loss: 0.2706 - accuracy: 0.3500 - val_loss: 0.4129 - val_accuracy: 0.3000\n",
            "Epoch 49/50\n",
            "13/13 [==============================] - 1s 70ms/step - loss: 0.2764 - accuracy: 0.3400 - val_loss: 0.3877 - val_accuracy: 0.3000\n",
            "Epoch 50/50\n",
            "13/13 [==============================] - 1s 71ms/step - loss: 0.2688 - accuracy: 0.3400 - val_loss: 0.3734 - val_accuracy: 0.3000\n",
            "Kappa Score: 0.5994256999282125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Average Kappa score after a 5-fold cross validation: \",np.around(np.array(results).mean(),decimals=3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckdBt2e1kgoq",
        "outputId": "d323bfef-bf7b-4261-b773-558c27ab5bf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Kappa score after a 5-fold cross validation:  0.574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "loss_train = history.history['loss']\n",
        "loss_val = history.history['val_loss']\n",
        "epochs = range(1,51)\n",
        "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
        "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "aqMutmwheoWg",
        "outputId": "7b4769cf-276e-4df8-9a03-51a04bc69323"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test)\n",
        "import matplotlib.pyplot as plt\n",
        "x=np.arange(0,62)\n",
        "plt.title(\"actual vs predicted score\")\n",
        "plt.xlabel(\"essays\")\n",
        "plt.ylabel(\"score\")\n",
        "\n",
        "plt.scatter(x,y_test.values,color='r',label=\"actual score\")\n",
        "plt.scatter(x,y_pred,color='b',label=\"predicted score\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "HBdokXj0eoTw",
        "outputId": "38b1823a-091a-4fe0-e7cc-8364aaa8dbdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1117    1\n",
            "1119    1\n",
            "1122    1\n",
            "1129    3\n",
            "1132    3\n",
            "       ..\n",
            "1382    1\n",
            "1385    1\n",
            "1404    3\n",
            "1415    3\n",
            "1416    1\n",
            "Name: Reviewer-1, Length: 62, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zi_PmJcjeoRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "du0fTfOXeoOn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}